{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pdb \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FramesDataset(Dataset):\n",
    "    def text2Tensor(self, file_data):\n",
    "        #process the file data such that it's a list of lists of offset tuple in each time step\n",
    "        file_data_t = []\n",
    "        data_temp = []\n",
    "        try:\n",
    "            frame_num = file_data[0][0]\n",
    "        except IndexError:\n",
    "            print(\"???:\")\n",
    "            print(file_data)\n",
    "        traj_list = []\n",
    "        frame_list = []\n",
    "        for line in file_data:\n",
    "            if frame_num != line[0]:\n",
    "                frame_num = line[0]\n",
    "                data_temp.sort(key=lambda data : data[1])\n",
    "                file_data_t.append(data_temp)\n",
    "                data_temp = [line]\n",
    "            else:    \n",
    "                data_temp.append(line)\n",
    "            #keep a traj list for all trajs\n",
    "            if line[1] not in traj_list:\n",
    "                traj_list.append(line[1])\n",
    "            if line[0] not in frame_list:\n",
    "                frame_list.append(line[0])\n",
    "        traj_list.sort()\n",
    "        frame_list.sort()  \n",
    "        \n",
    "        #get participants in each frame\n",
    "        #@note here the elements are ped's index in the traj list\n",
    "        participants = [[] for i in range(len(file_data_t))]\n",
    "        for frame_idx, line in enumerate(file_data_t):\n",
    "            for traj_idx, traj in enumerate(traj_list):\n",
    "                in_flag = False\n",
    "                for data in line:\n",
    "                    if data[1] == traj:\n",
    "                        in_flag = True\n",
    "                        participants[frame_idx].append(traj_list.index(data[1]))\n",
    "                if not in_flag:\n",
    "                    file_data_t[frame_idx].append([frame_list[frame_idx], traj, 0., 0.])\n",
    "            file_data_t[frame_idx].sort(key=lambda data : data[1])\n",
    "\n",
    "        file_data_tensors = torch.tensor(file_data_t, device=device)\n",
    "        \n",
    "        participant_masks = []\n",
    "        for frame_idx, line in enumerate(participants):\n",
    "            participant_masks.append([[torch.tensor(1.) if i in participants[frame_idx] else torch.tensor(0.) for i in range(len(traj_list))]])\n",
    "        participant_masks = torch.tensor(participant_masks, device=device)\n",
    "        \n",
    "        return traj_list, participant_masks, file_data_tensors              \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    @func preprocess\n",
    "    @param path: relative path for the raw data\n",
    "    @note raw data~ col1: frame index, col2: traj index, (col3, col4): (y, x)\n",
    "    @return traj_list: indices for each trajactory in raw data\n",
    "            participants_masks~tensor(frame num x traj num): indicate the presence of each ped at each frame\n",
    "            file_data_tensors~tensor(frame num x traj num x 4): the position of each traj at each frame\n",
    "                                                                if not present default to (0,0)\n",
    "    '''\n",
    "    def preprocess(self, path):\n",
    "        #open the file as it is\n",
    "        file_data = []\n",
    "        with open(path, 'r') as file:\n",
    "            for line in file:\n",
    "                line_data = [int(float(data)) if i < 2 else float(data) for i, data in enumerate(line.rsplit())]\n",
    "                line_data[2], line_data[3] = line_data[3], line_data[2]\n",
    "                file_data.append(line_data)\n",
    "        file_data = sorted(file_data, key=lambda data : data[1])\n",
    "        file_data_sort = sorted(file_data, key=lambda data : data[0])\n",
    "        \n",
    "        traj_list, participant_masks, coord_tensors = self.text2Tensor(file_data_sort)\n",
    "        \n",
    "        #process the file data such that it contains the offsets not global coords\n",
    "        file_data_off = []\n",
    "        for i, line in enumerate(file_data):\n",
    "            if i > 0:\n",
    "                if file_data[i][1] == file_data[i-1][1]:\n",
    "                    file_data_off.append([file_data[i][0], file_data[i][1], file_data[i][2]-file_data[i-1][2], file_data[i][3]-file_data[i-1][3]])\n",
    "        file_data_off.sort(key=lambda data : data[0])        \n",
    "        \n",
    "        traj_list, participant_masks, off_tensors = self.text2Tensor(file_data_off)\n",
    "        \n",
    "        return traj_list, participant_masks, off_tensors, coord_tensors\n",
    "    \n",
    "\n",
    "    def __init__(self, path):\n",
    "        self.traj_list, self.participant_masks, self.off_data, self.coord_data = self.preprocess(path)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.off_data)\n",
    "    \n",
    "\n",
    "    '''\n",
    "    @note (X, Y) is a (file_data[idx], frame[idx+1]) pair if a single idx is provided\n",
    "    a (frame[idx.start]2frame[idx.end], frame[idx.start+1]2frame[idx.end+1]) pair is provided\n",
    "    if a index slice is provided\n",
    "    the accompanying mask tensor follows the same rule \n",
    "    '''\n",
    "    def __getitem__(self, idx):\n",
    "        participant_mask = self.participant_masks[idx]\n",
    "        X = self.off_data[idx]\n",
    "        Z = torch.zeros(*X.shape)\n",
    "        for coords in self.coord_data:\n",
    "            if coords[0][0] == X[0][0]:\n",
    "                Z = coords\n",
    "        ret_data = {}\n",
    "        ret_data[\"seq\"] = X\n",
    "        ret_data[\"mask\"] = participant_mask\n",
    "        ret_data[\"idx\"] = idx\n",
    "        ret_data[\"coords\"] = Z\n",
    "        return ret_data\n",
    "\n",
    "    \n",
    "    def getTrajList(self):\n",
    "        return self.traj_list\n",
    "\n",
    "    \n",
    "    def getParticipants(self):\n",
    "        return self.participant_mask\n",
    "    \n",
    "    \n",
    "    def getCoordinates(self, seq):\n",
    "        #get the coord data at the time step right before the seq starts\n",
    "        before_coords = torch.empty(len(self.traj_list), 4, device=device)\n",
    "        for x in seq:\n",
    "            for i, coords in enumerate(self.coord_data):\n",
    "                if coords[0][0] == x[0][0]:\n",
    "                    before_coords = self.coord_data[i-1]\n",
    "                    break\n",
    "            break\n",
    "        ret_data = torch.reshape(before_coords, (1, before_coords.shape[0], before_coords.shape[1])) \n",
    "        #get the rest\n",
    "        for i, x in enumerate(seq):\n",
    "            for j, coords in enumerate(self.coord_data):\n",
    "                if coords[0][0] == x[0][0]:\n",
    "                    coords_reshaped = torch.reshape(coords.clone(), (1, before_coords.shape[0], before_coords.shape[1]))                     \n",
    "                    ret_data = torch.cat((ret_data, coords_reshaped), 0)\n",
    "                    break\n",
    "        return ret_data\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# D = FramesDataset(\"try_dataset.txt\")\n",
    "# Dloader = DataLoader(D, batch_size=20)\n",
    "\n",
    "# for i, data in enumerate(Dloader):\n",
    "#     if i == 0:\n",
    "#         print(f\"idx {data['idx']}\")\n",
    "#         print(f\"X {data['seq'].shape}\\n\")\n",
    "#         for i in data['seq']:\n",
    "#             print(i)\n",
    "#         print(f\"mask\\n {data['mask']}\")\n",
    "#         print(f\"coords {data['coords'].shape}\\n\")   \n",
    "#         for i in data['coords']:\n",
    "#             print(i)       \n",
    "#         print(\"\\n\\n\\n\\ntemp \\n\\n\")\n",
    "#         temp = D.getCoordinates(data['seq'])\n",
    "#         for i in temp:\n",
    "#             print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Phi(nn.Module):\n",
    "    ''' a non-linear layer'''\n",
    "    def __init__(self, dropout_prob):\n",
    "        super(Phi, self).__init__()\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.Dropout = nn.Dropout(p=dropout_prob)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.Dropout(self.ReLU(x))\n",
    "\n",
    "\n",
    "class VanillaLSTM(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dim=20, mediate_dim=10, output_dim=2, traj_num=3, dropout_prob=0.2):\n",
    "        super(VanillaLSTM, self).__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.traj_num = traj_num\n",
    "        self.InputLayer = nn.Linear(input_dim, mediate_dim)\n",
    "        self.LSTMCell = nn.LSTMCell(mediate_dim, hidden_dim)\n",
    "        self.OutputLayer = nn.Linear(hidden_dim, output_dim)\n",
    "        self.Phi = Phi(dropout_prob=dropout_prob)\n",
    "\n",
    "\n",
    "    def forward(self, X, part_masks, all_h_t, all_c_t, Y, T_obs, T_pred):\n",
    "        outputs = torch.empty(X.shape[0], X.shape[1], self.output_dim, device=device)\n",
    "        for frame_idx, x in enumerate(X):      \n",
    "            if frame_idx > T_pred:\n",
    "                outputs[frame_idx] = torch.zeros(X.shape[1], self.output_dim)\n",
    "                continue\n",
    "                \n",
    "            elif frame_idx <= T_obs:\n",
    "                r = self.Phi(self.InputLayer(x[:,2:]))\n",
    "                all_h_t, all_c_t = self.LSTMCell(r, (all_h_t, all_c_t))\n",
    "                part_mask = torch.t(part_masks[frame_idx]).expand(part_masks[frame_idx].shape[1], self.output_dim)\n",
    "                outputs[frame_idx] = self.OutputLayer(all_h_t) * part_mask\n",
    "                \n",
    "            elif frame_idx > T_obs and frame_idx <= T_pred:\n",
    "#                 r = self.Phi(self.InputLayer(outputs[frame_idx-1].clone()))\n",
    "                r = self.Phi(self.InputLayer(outputs[frame_idx-1]))\n",
    "                all_h_t, all_c_t = self.LSTMCell(r, (all_h_t, all_c_t))\n",
    "                part_mask = torch.t(part_masks[frame_idx]).expand(part_masks[frame_idx].shape[1], self.output_dim)\n",
    "                outputs[frame_idx] = self.OutputLayer(all_h_t) * part_mask                \n",
    "                \n",
    "            #dirty fix for appearance that's too short\n",
    "            if frame_idx > 3 and frame_idx > T_obs:\n",
    "                for traj_idx in torch.where(part_masks[frame_idx][0] != 0)[0]:\n",
    "                    if part_masks[frame_idx-3][0][traj_idx] == 0:\n",
    "                        outputs[frame_idx, traj_idx] = Y[frame_idx, traj_idx] \n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajPruning(part_mask, ratio=0.6, in_tensor=None):\n",
    "    if in_tensor != None:\n",
    "        #count appearance\n",
    "        for traj in range(in_tensor.shape[1]):\n",
    "            traj_mask = part_mask[:,0,traj]\n",
    "            count = traj_mask[traj_mask!=0].shape[0]\n",
    "            if count < part_mask.shape[0]*ratio:\n",
    "                in_tensor[:,traj,:] *= 0.\n",
    "        return in_tensor\n",
    "    else:\n",
    "        new_mask = part_mask.clone()\n",
    "        #count appearance\n",
    "        for traj in range(part_mask.shape[2]):\n",
    "            traj_mask = part_mask[:,0,traj]\n",
    "            count = traj_mask[traj_mask!=0].shape[0]\n",
    "            if count < part_mask.shape[0]*ratio:\n",
    "                new_mask[:,0,traj] *= 0.        \n",
    "        return new_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(T_obs, T_pred, file, model=None, name=\"model\"):\n",
    "    tic = time.time()\n",
    "    print(f\"training on {file}\")    \n",
    "    \n",
    "    h_dim = 1024\n",
    "    batch_size = T_pred\n",
    "\n",
    "    #try to train this\n",
    "#     dataset = FramesDataset(\"crowds_zara02.txt\")\n",
    "    dataset = FramesDataset(file)\n",
    "    #a dataloader for now not sure how to use\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    traj_num = len(dataset.getTrajList())\n",
    "    h = torch.zeros(traj_num, h_dim, device=device)\n",
    "    c = torch.zeros(traj_num, h_dim, device=device)\n",
    "\n",
    "    if model == None:\n",
    "        print(\"instantiating model\")\n",
    "        vl = VanillaLSTM(hidden_dim=h_dim, mediate_dim=128, output_dim=2, traj_num=traj_num)\n",
    "    else:\n",
    "        vl = model\n",
    "    vl.to(device)\n",
    "\n",
    "    #define loss & optimizer\n",
    "    criterion = nn.MSELoss(reduction=\"sum\")\n",
    "    # criterion = Gaussian2DNll\n",
    "#     optimizer = torch.optim.Adagrad(vl.parameters(), weight_decay=0.0005)\n",
    "    optimizer = torch.optim.Adam(vl.parameters(), weight_decay=0.0005)\n",
    "\n",
    "    plot_data = [[] for _ in range(len(dataset) // batch_size)]\n",
    "    #sequentially go over the dataset batch_size by batch_size\n",
    "    EPOCH = 10\n",
    "    for epoch in range(EPOCH):\n",
    "        print(f\"epoch {epoch+1}/{EPOCH}  \")\n",
    "        for batch_idx, data in enumerate(dataloader):\n",
    "            print(f\"batch {batch_idx+1}/{len(dataset) // batch_size} \", end='\\r')\n",
    "            if batch_idx < len(dataset) // batch_size:\n",
    "                Y = data['seq'][:T_pred][:T_pred,:,2:].clone()\n",
    "                input_seq = data['seq'][:T_pred].clone()\n",
    "                part_masks = data['mask']\n",
    "                with torch.autograd.set_detect_anomaly(True):\n",
    "                    #dirty truncate\n",
    "                    run_ratio = (T_obs+3)/T_pred\n",
    "                    input_seq = trajPruning(part_masks, ratio=run_ratio, in_tensor=input_seq) \n",
    "                    Y = trajPruning(part_masks, ratio=run_ratio, in_tensor=Y)     \n",
    "                    pr_masks = trajPruning(part_masks, ratio=run_ratio)                    \n",
    "                    \n",
    "                    #forward prop\n",
    "                    output = vl(input_seq, pr_masks, h, c, Y, T_obs, T_pred)\n",
    "\n",
    "                    #compute loss\n",
    "                    Y_pred = output[T_obs+1:T_pred]\n",
    "                    Y_g = Y[T_obs+1:T_pred]\n",
    "\n",
    "                    cost = criterion(Y_pred, Y_g)\n",
    "\n",
    "                    if epoch % 10 == 9:\n",
    "                        print(epoch, batch_idx, cost.item())\n",
    "\n",
    "                    #save data for plotting\n",
    "                    plot_data[batch_idx].append(cost.item())\n",
    "\n",
    "                    #backward prop\n",
    "                    optimizer.zero_grad()\n",
    "                    cost.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "    toc = time.time()\n",
    "    print(f\"training consumed {toc-tic}\")\n",
    "\n",
    "    #plot the cost\n",
    "    plt.figure()\n",
    "    for data in plot_data:\n",
    "        plt.plot(np.arange(len(plot_data[0])), data)\n",
    "    \n",
    "    #save the model\n",
    "    torch.save(vl, name)\n",
    "    print(f\"saved model in {name}\\n\")    \n",
    "\n",
    "    return vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, T_obs, T_pred, file):\n",
    "    #try to validate this\n",
    "    h_dim = 1024\n",
    "\n",
    "    batch_size = T_pred\n",
    "\n",
    "#     dataset = FramesDataset(\"crowds_zara02.txt\")\n",
    "    dataset = FramesDataset(file)    \n",
    "    #a dataloader for now not sure how to use\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "    traj_num = len(dataset.getTrajList())\n",
    "    h = torch.zeros(traj_num, h_dim, device=device)\n",
    "    c = torch.zeros(traj_num, h_dim, device=device)\n",
    "    \n",
    "    plotting_batches = np.arange(40)\n",
    "    plotting_data = []\n",
    "    avgDispErrMeans = []\n",
    "    finalDispErrMeans = []    \n",
    "    #validate the model based on the dataset\n",
    "    print(f\"validating on {file}\")\n",
    "    for batch_idx, data in enumerate(dataloader):\n",
    "        if batch_idx < len(dataset) // batch_size:\n",
    "            Y = data['seq'][:T_pred,:,2:].clone()\n",
    "            input_seq = data['seq'][:T_pred].clone()\n",
    "            part_masks = data['mask']            \n",
    "            with torch.no_grad():         \n",
    "                print(f\"batch {batch_idx+1}/{len(dataset) // batch_size}  \", end='\\r')\n",
    "                #dirty truncate\n",
    "                run_ratio = (T_obs+3)/T_pred\n",
    "                input_seq = trajPruning(part_masks, ratio=run_ratio, in_tensor=input_seq) \n",
    "                Y = trajPruning(part_masks, ratio=run_ratio, in_tensor=Y)     \n",
    "                pr_masks = trajPruning(part_masks, ratio=run_ratio)\n",
    "                \n",
    "                #forward prop\n",
    "                output = model(input_seq, pr_masks, h, c, Y, T_obs, T_pred)\n",
    "\n",
    "                #compute cost\n",
    "                Y_pred = output[T_obs+1:T_pred]\n",
    "                Y_g = Y[T_obs+1:T_pred]\n",
    "                #......\n",
    "\n",
    "                #get and process result                \n",
    "                Y_pred_param = Y_pred.clone()\n",
    "                coords_param = dataset.getCoordinates(data['seq']).clone()\n",
    "\n",
    "                #save plotting data for visualization\n",
    "                if batch_idx in plotting_batches:\n",
    "                    plotting_data.append((Y_pred, part_masks, traj_num, batch_idx, dataset.getCoordinates(data['seq']), T_obs, True))\n",
    "                    plotting_data.append((Y_pred_param, part_masks, traj_num, batch_idx, dataset.getCoordinates(data['seq']), T_obs, False))                    \n",
    "\n",
    "                if batch_idx in range(len(dataset) // batch_size-1):\n",
    "                    err = avgDispError(Y_pred_param, part_masks, traj_num, batch_idx, dataset.getCoordinates(data['seq']), T_obs)\n",
    "                    avgDispErrMeans.append(err)\n",
    "\n",
    "                if batch_idx in range(len(dataset) // batch_size-1):\n",
    "                    err = finalDispError(Y_pred_param, part_masks, traj_num, batch_idx, dataset.getCoordinates(data['seq']), T_obs)\n",
    "                    finalDispErrMeans.append(err)                \n",
    "        \n",
    "    for d in plotting_data:\n",
    "        plotting_batch(*d)\n",
    "        \n",
    "    print(\"total avg disp mean \", np.sum(np.array(avgDispErrMeans))/len([v for v in avgDispErrMeans if v != 0]))\n",
    "    print(\"total final disp mean \", np.sum(np.array(finalDispErrMeans))/len([v for v in finalDispErrMeans if v != 0]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "@param trajs~(frame_num of a batch x traj_num x 2)\n",
    "'''\n",
    "def plotting_batch(batch_trajs_pred_gpu, part_masks, traj_num, batch_idx, coord_data, T_obs, is_total):          \n",
    "    #reform the trajs tensor to a list of each traj's pos at each frame\n",
    "    batch_trajs_pred = batch_trajs_pred_gpu.cpu().data.numpy()\n",
    "    trajs_pred_list = [np.array([]) for _ in range(traj_num)]\n",
    "    parts = []\n",
    "    for frame_idx, trajs_pred in enumerate(batch_trajs_pred):\n",
    "        for traj_idx, pos_pred in enumerate(trajs_pred):\n",
    "            if not (pos_pred == np.array([0., 0.])).all():\n",
    "                if traj_idx not in parts:\n",
    "                    parts.append(traj_idx)\n",
    "                    trajs_pred_list[int(traj_idx)] = np.array(pos_pred)  \n",
    "                else:\n",
    "                    trajs_pred_list[int(traj_idx)] = np.vstack((trajs_pred_list[int(traj_idx)], pos_pred))\n",
    "            \n",
    "    #calc the coords of each step for plotting\n",
    "    batch_coords = coord_data.cpu().data.numpy()\n",
    "    split_points = np.array(batch_coords[T_obs+1,:,2:])    \n",
    "    trajs_pred_coords = []\n",
    "    for traj_idx, traj in enumerate(trajs_pred_list):\n",
    "        traj_pred_coord = np.array(split_points[traj_idx])\n",
    "        temp_point = np.array(split_points[traj_idx])\n",
    "        for off in traj:\n",
    "            next_point = temp_point + off\n",
    "            traj_pred_coord = np.vstack((traj_pred_coord, next_point))\n",
    "            temp_point = next_point\n",
    "        trajs_pred_coords.append(traj_pred_coord)\n",
    "        \n",
    "    #plot\n",
    "    plt.figure(figsize=(12,12))\n",
    "    plot_idx = 0\n",
    "    for traj_idx in parts:\n",
    "        try:\n",
    "            pred_x = trajs_pred_coords[traj_idx][:,0]\n",
    "        except IndexError:\n",
    "            print(\"not enough appearance\")\n",
    "            continue\n",
    "        pred_y = trajs_pred_coords[traj_idx][:,1]            \n",
    "        plt.plot(pred_x, pred_y, label=\"pred\"+str(traj_idx), marker=\".\")\n",
    "        for i, (x, y) in enumerate(zip(pred_x, pred_y)):\n",
    "            if i < len(pred_x)-1:\n",
    "                try:\n",
    "                    plt.arrow(x, y, (pred_x[i+1] - x)/2, (pred_y[i+1] - y)/2, width=0.0001, head_width=0.001, head_length=0.001)    \n",
    "                except IndexError:\n",
    "                    print(\"plot error\")\n",
    "\n",
    "        total_x = batch_coords[:,traj_idx,2]        \n",
    "        total_x = total_x[np.where(total_x != 0.)]\n",
    "        total_y = batch_coords[:,traj_idx,3]\n",
    "        total_y = total_y[np.where(total_y != 0.)]       \n",
    "        try:\n",
    "            plt.plot(total_x, total_y, linestyle=\"dashed\", label=\"total\"+str(traj_idx), marker=\".\")\n",
    "        except ValueError:\n",
    "            print(\"plot error\")\n",
    "            \n",
    "        for i, (x, y) in enumerate(zip(total_x, total_y)):\n",
    "            if i < len(total_x)-1:\n",
    "                try:\n",
    "                    plt.arrow(x, y, (total_x[i+1] - x)/2, (total_y[i+1] - y)/2, width=0.0001, head_width=0.001, head_length=0.001)\n",
    "                except IndexError:\n",
    "                    print(\"plot error\")\n",
    "        plot_idx += 1\n",
    " \n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(f\"batch {batch_idx}\")\n",
    "    plt.savefig(\"eth_plots/\"+str(batch_idx)+str(is_total))\n",
    "    \n",
    "    \n",
    "def avgDispError(batch_trajs_pred_gpu, part_masks, traj_num, batch_idx, coord_data, T_obs):\n",
    "    #reform the trajs tensor to a list of each traj's pos at each frame\n",
    "    batch_trajs_pred = batch_trajs_pred_gpu.cpu().data.numpy()\n",
    "    trajs_pred_list = [np.array([]) for _ in range(traj_num)]\n",
    "    parts = []\n",
    "    for frame_idx, trajs_pred in enumerate(batch_trajs_pred):\n",
    "        for traj_idx, pos_pred in enumerate(trajs_pred):\n",
    "            if not (pos_pred == np.array([0., 0.])).all():\n",
    "                if traj_idx not in parts:\n",
    "                    parts.append(traj_idx)\n",
    "                    trajs_pred_list[int(traj_idx)] = np.array(pos_pred)  \n",
    "                else:\n",
    "                    trajs_pred_list[int(traj_idx)] = np.vstack((trajs_pred_list[int(traj_idx)], pos_pred))\n",
    "            \n",
    "    #calc the coords of each step\n",
    "    batch_coords = coord_data.cpu().data.numpy()\n",
    "    split_points = np.array(batch_coords[T_obs+1,:,2:])    \n",
    "    trajs_pred_coords = []\n",
    "    for traj_idx, traj in enumerate(trajs_pred_list):\n",
    "        traj_pred_coord = np.array(split_points[traj_idx])\n",
    "        temp_point = np.array(split_points[traj_idx])\n",
    "        for off in traj:\n",
    "            next_point = temp_point + off\n",
    "            traj_pred_coord = np.vstack((traj_pred_coord, next_point))\n",
    "            temp_point = next_point\n",
    "        trajs_pred_coords.append(traj_pred_coord)   \n",
    "        \n",
    "    \n",
    "    #compare\n",
    "    trajs_dist = []\n",
    "    step_num = 0\n",
    "    for traj_idx, traj in enumerate(parts):\n",
    "        T_valid = T_obs+1+trajs_pred_coords[traj].shape[0]\n",
    "        diff = batch_coords[T_obs+1:T_valid,traj,2:] - trajs_pred_coords[traj]\n",
    "        traj_dist = np.sum(np.linalg.norm(diff, axis=1))        \n",
    "        if not math.isnan(traj_dist):\n",
    "            trajs_dist.append(traj_dist)\n",
    "            step_num += diff.shape[0]\n",
    "\n",
    "    if len(trajs_dist) != 0:\n",
    "        mean_of_trajs_mean = np.sum(np.array(trajs_dist))/step_num\n",
    "    else:\n",
    "        mean_of_trajs_mean = 0\n",
    " \n",
    "    print(f\"avgDispError {mean_of_trajs_mean}\")\n",
    "    return mean_of_trajs_mean\n",
    "\n",
    "\n",
    "def finalDispError(batch_trajs_pred_gpu, part_masks, traj_num, batch_idx, coord_data, T_obs):\n",
    "    #reform the trajs tensor to a list of each traj's pos at each frame\n",
    "    batch_trajs_pred = batch_trajs_pred_gpu.cpu().data.numpy()\n",
    "    trajs_pred_list = [np.array([]) for _ in range(traj_num)]\n",
    "    parts = []\n",
    "    for frame_idx, trajs_pred in enumerate(batch_trajs_pred):\n",
    "        for traj_idx, pos_pred in enumerate(trajs_pred):\n",
    "            if not (pos_pred == np.array([0., 0.])).all():\n",
    "                if traj_idx not in parts:\n",
    "                    parts.append(traj_idx)\n",
    "                    trajs_pred_list[int(traj_idx)] = np.array(pos_pred)  \n",
    "                else:\n",
    "                    trajs_pred_list[int(traj_idx)] = np.vstack((trajs_pred_list[int(traj_idx)], pos_pred))\n",
    "            \n",
    "    #calc the coords of each step\n",
    "    batch_coords = coord_data.cpu().data.numpy()\n",
    "    split_points = np.array(batch_coords[T_obs+1,:,2:])    \n",
    "    trajs_pred_coords = []\n",
    "    for traj_idx, traj in enumerate(trajs_pred_list):\n",
    "        traj_pred_coord = np.array(split_points[traj_idx])\n",
    "        temp_point = np.array(split_points[traj_idx])\n",
    "        for off in traj:\n",
    "            next_point = temp_point + off\n",
    "            traj_pred_coord = np.vstack((traj_pred_coord, next_point))\n",
    "            temp_point = next_point\n",
    "        trajs_pred_coords.append(traj_pred_coord)   \n",
    "        \n",
    "    \n",
    "    #compare\n",
    "    trajs_dist = []\n",
    "    for traj_idx, traj in enumerate(parts):\n",
    "        T_valid = T_obs+1+trajs_pred_coords[traj].shape[0]\n",
    "        diff = batch_coords[T_obs+1:T_valid,traj,2:] - trajs_pred_coords[traj]\n",
    "        final_diff = diff[-1]\n",
    "        traj_dist = np.linalg.norm(final_diff)       \n",
    "        if not math.isnan(traj_dist):\n",
    "            trajs_dist.append(traj_dist)\n",
    "\n",
    "    if len(trajs_dist) != 0:\n",
    "        mean_of_trajs_final = np.mean(np.array(trajs_dist))\n",
    "    else:\n",
    "        mean_of_trajs_final = 0\n",
    " \n",
    "    print(f\"finalDispError {mean_of_trajs_final}\")\n",
    "    return mean_of_trajs_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n",
      "\n",
      "training on try_dataset1.txt\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6e575aa9e3dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"try_dataset1.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"try_dataset1.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-381ec1fa3e21>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(T_obs, T_pred, file, model, name)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#try to train this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#     dataset = FramesDataset(\"crowds_zara02.txt\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFramesDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#a dataloader for now not sure how to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4b91ed8c9b76>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraj_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparticipant_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moff_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoord_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4b91ed8c9b76>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mfile_data_sort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mtraj_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparticipant_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext2Tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_data_sort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m#process the file data such that it contains the offsets not global coords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-4b91ed8c9b76>\u001b[0m in \u001b[0;36mtext2Tensor\u001b[0;34m(self, file_data)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mfile_data_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mfile_data_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_data_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mparticipant_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"device {device}\\n\") \n",
    "\n",
    "#     train_datasets = [\"datasets/eth/train\",\n",
    "#                       \"datasets/hotel/train\",               \n",
    "#                       \"datasets/univ/train\",\n",
    "#                       \"datasets/zara1/train\",\n",
    "#                       \"datasets/zara2/train\"\n",
    "#                      ]\n",
    "#     val_datasets = [\"datasets/eth/test\",\n",
    "#                     \"datasets/hotel/test\",               \n",
    "#                     \"datasets/univ/test\",\n",
    "#                     \"datasets/zara1/test\",\n",
    "#                     \"datasets/zara2/test\"\n",
    "#                     ]\n",
    "#     names = [\"eth_vl.pt\",\n",
    "#              \"hotel_vl.pt\",\n",
    "#              \"univ_vl.pt\",\n",
    "#              \"zara1_vl.pt\",\n",
    "#              \"zara2_vl.pt\"\n",
    "#             ]\n",
    "    \n",
    "#     for train_dataset, val_dataset, name in zip(train_datasets, val_datasets, names):\n",
    "#         #preparing training set\n",
    "#         files_dir = train_dataset\n",
    "#         print(f\"pulling from dir {files_dir}\")\n",
    "#         files = [join(files_dir, f) for f in listdir(files_dir) if isfile(join(files_dir, f))]\n",
    "#         vl = None\n",
    "#         #training\n",
    "#         for file in files:\n",
    "#             vl = train(8, 20, file, model=vl, name=name)\n",
    "\n",
    "#         vl1 = torch.load(name)\n",
    "#         print(f\"loading from {name}\")\n",
    "#     #     validate(vl1, 8, 20, \"try_dataset.txt\")       \n",
    "#         #preparing validating set\n",
    "#         files_dir = val_dataset\n",
    "#         print(f\"pulling from dir {files_dir}\")        \n",
    "#         files = [join(files_dir, f) for f in listdir(files_dir) if isfile(join(files_dir, f))]\n",
    "#         #validating\n",
    "#         for file in files:\n",
    "#             validate(vl1, 8, 20, file)   \n",
    "            \n",
    "#         print(\"====================================\")\n",
    "\n",
    "#     files_dir = \"datasets/eth/train\"\n",
    "#     name = \"eth_vl.pt\"\n",
    "#     print(f\"pulling from dir {files_dir}\")\n",
    "#     files = [join(files_dir, f) for f in listdir(files_dir) if isfile(join(files_dir, f))]\n",
    "#     vl = None\n",
    "#     #training\n",
    "#     for file in files:\n",
    "#         vl = train(8, 20, file, model=vl, name=name)\n",
    "\n",
    "#     torch.cuda.empty_cache()\n",
    "#     vl1 = torch.load(\"eth_vl.pt\")\n",
    "#     print(f\"loading from eth_vl.pt\")\n",
    "# #     validate(vl1, 8, 20, \"try_dataset.txt\")       \n",
    "#     #preparing validating set\n",
    "#     files_dir = \"datasets/eth/test\"\n",
    "#     print(f\"pulling from dir {files_dir}\")        \n",
    "#     files = [join(files_dir, f) for f in listdir(files_dir) if isfile(join(files_dir, f))]\n",
    "#     #validating\n",
    "#     for file in files:\n",
    "#         validate(vl1, 8, 20, file) \n",
    "\n",
    "\n",
    "    temp = train(8, 20, \"try_dataset1.txt\")\n",
    "    validate(temp, 8, 20, \"try_dataset1.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit11d574a7b6b045d2a23081aa8b3640ac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
